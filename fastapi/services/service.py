# FastAPI ê´€ë ¨
from fastapi import UploadFile, File
from fastapi.responses import JSONResponse


# ê¸°íƒ€ ì™¸ë¶€ íŒ¨í‚¤ì§€
import openai
import boto3
import uuid
import os

# ë‚´ë¶€ ìœ í‹¸ / í™˜ê²½
from dotenv import load_dotenv
from logs.logs import logger
from db.insert import insert_row

from utils.s3 import get_s3_client, get_s3_bucket_name, upload_file_to_s3

s3 = get_s3_client()
bucket_name = get_s3_bucket_name()

load_dotenv()  # .env íŒŒì¼ì—ì„œ OPENAI_API_KEY ë¡œë“œ

client = openai.OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

ALLOWED_EXTENSIONS = (".wav", ".mp3", ".m4a")
MAX_FILE_SIZE_MB = 50
MAX_FILE_SIZE = MAX_FILE_SIZE_MB * 1024 * 1024

def handle_gpt(request):
    try:
        response = client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[
                {"role": "system", "content": "ë„ˆëŠ” íŒŒì¼ ì²˜ë¦¬ ë„ìš°ë¯¸ì•¼."},
                {"role": "user", "content": request.prompt}
            ]
        ) 
        gpt_reply = response.choices[0].message.content
        return {"reply": gpt_reply}
    except Exception as e:
        return {"error": str(e)}

async def handle_upload(file: UploadFile):
    try:
        logger.info(f"ğŸ“¦ ìˆ˜ì‹ ëœ íŒŒì¼: {file.filename}")

        # í™•ì¥ì ê²€ì‚¬
        if not file.filename.lower().endswith(ALLOWED_EXTENSIONS):
            logger.warning("â›” ì§€ì›í•˜ì§€ ì•ŠëŠ” íŒŒì¼ í™•ì¥ì")
            return JSONResponse(
                status_code=400,
                content={"error": f"ì§€ì›í•˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹ì…ë‹ˆë‹¤. í—ˆìš©: {ALLOWED_EXTENSIONS}"}
            )
        # íŒŒì¼ í¬ê¸° ì²´í¬
        file.file.seek(0, 2)  # EOFë¡œ ì´ë™
        file_size = file.file.tell()
        file.file.seek(0)  # ë‹¤ì‹œ ì²˜ìŒìœ¼ë¡œ

        if file_size > MAX_FILE_SIZE:
            logger.warning(f"â›” íŒŒì¼ ìš©ëŸ‰ ì´ˆê³¼: {file.filename} ({file_size} bytes)")
            return JSONResponse(
                status_code=413,
                content={"error": f"{MAX_FILE_SIZE_MB}MB ì´í•˜ íŒŒì¼ë§Œ ì—…ë¡œë“œ ê°€ëŠ¥í•©ë‹ˆë‹¤."}
            )

        upload_uuid = uuid.uuid4()

        # ì²´í¬ì„¬ ë¨¼ì € ê³„ì‚°
        # hasher = hashlib.md5()
        # while chunk := await file.read(8192):
        #     hasher.update(chunk)
        # checksum = hasher.hexdigest()
        # await file.seek(0)

        # S3 ì—…ë¡œë“œ 
        s3_folder = "uploads/"
        s3_filename = f"{upload_uuid}_{file.filename}"
        s3_key = f"{s3_folder}{s3_filename}"
        
        insert_row("metadata.s3_file_metadata", {
            "upload_uuid": str(upload_uuid),
            "original_filename": file.filename,
            "s3_folder_path": s3_folder,
            "s3_filename": s3_filename,
            "file_size": file.size,
            "file_type": file.content_type,
            # "checksum": checksum
        })

        upload_file_to_s3(file.file, s3_key)
        logger.info(f"âœ… S3 ì—…ë¡œë“œ ì„±ê³µ: {s3_filename}")

        return {
            "upload_uuid": str(upload_uuid),
            "status": "uploaded"
        }

    # except ValueError as ve:
    #     if "ì¤‘ë³µëœ íŒŒì¼ì…ë‹ˆë‹¤" in str(ve):
    #         logger.warning(f"â›” ì¤‘ë³µ ì—…ë¡œë“œ ì°¨ë‹¨: {file.filename}")
    #         return JSONResponse(
    #             status_code=409,
    #             content={"status": "duplicate", "detail": str(ve)}
    #         )
    #     else:
    #         logger.error(f"âŒ ì²˜ë¦¬ ì¤‘ ValueError: {ve}", exc_info=True)
    #         return {"error": str(ve)}

    except Exception as e:
        logger.error(f"âŒ ì—…ë¡œë“œ ì‹¤íŒ¨: {e}", exc_info=True)
        return {"error": str(e)}
